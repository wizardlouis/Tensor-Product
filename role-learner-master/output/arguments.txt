batch_size: 32
bidirectional: False
burn_in: 0
data_path: data
data_prefix: example
decoder: ltr
decoder_embedding_size: 20
decoder_prefix: None
decoder_task: auto
digits: True
embed_squeeze: None
embedding_file: None
extra_test_set: None
filler_dim: 10
final_linear: True
hidden_size: 60
l2_norm_regularization_weight: 1.0
neighbor_analysis: True
num_roles: 20
one_hot_regularization_weight: 1.0
output_dir: output
patience: 10
pretrained_filler_embedding: None
role_assigner_num_layers: 1
role_assignment_shrink_filler_dim: None
role_dim: 20
role_learning: False
role_prefix: None
role_scheme: bi
save_role_dicts: False
save_vectors: False
scan_checkpoint: None
shuffle: False
softmax_roles: False
test_decoder: False
train: True
unique_role_regularization_weight: 1.0
unseen_words: zero
use_one_hot_temperature: False
vocab_size: 10
